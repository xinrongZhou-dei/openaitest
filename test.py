#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
AIå…¨èƒ½æ•™å¸ˆWebç³»ç»Ÿ
æ”¯æŒå¤šæ™ºèƒ½ä½“åä½œã€ä¸Šä¸‹æ–‡ç®¡ç†ã€å·¥å…·è°ƒç”¨ç­‰åŠŸèƒ½
"""

import os
import json
import uuid
import asyncio
from datetime import datetime
from typing import Dict, List, Any, Optional

from flask import Flask, render_template, request, jsonify, session
import requests
from werkzeug.utils import secure_filename
import openai
from agents import (
    Agent, Runner, AsyncComputer, ComputerTool, ModelSettings, 
    Button, Environment, WebSearchTool, ImageGenerationTool
)
# è¯­éŸ³è½¬æ–‡å­—ï¼ˆä½¿ç”¨ OpenAI Whisper API ä½œä¸ºå…¼å®¹å®ç°ï¼‰
try:
    from openai import OpenAI  # æ–°ç‰ˆOpenAI SDK
    _voice_client = OpenAI()
    def _transcribe_file_local(audio_path: str) -> str:
        # å¦‚æœæ²¡æœ‰æ‰©å±•åï¼Œå¤åˆ¶ä¸€ä»½å¸¦ .m4a ä¸´æ—¶æ–‡ä»¶ï¼Œè§„é¿æœåŠ¡ç«¯æ ¼å¼æ¢æµ‹å¤±è´¥
        temp_path = None
        if not os.path.splitext(audio_path)[1]:
            temp_path = audio_path + '.m4a'
            try:
                import shutil
                shutil.copyfile(audio_path, temp_path)
                audio_path = temp_path
            except Exception:
                pass
        with open(audio_path, 'rb') as af:
            res = _voice_client.audio.transcriptions.create(model='whisper-1', file=af)
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except Exception:
                pass
        return getattr(res, 'text', '') or (res.get('text') if isinstance(res, dict) else '')
except Exception:
    # æ—§ç‰ˆSDKæˆ–ç¯å¢ƒä¸å…¼å®¹æ—¶ï¼Œå›é€€åˆ° openai.Audio.transcriptions.create
    def _transcribe_file_local(audio_path: str) -> str:
        try:
            with open(audio_path, 'rb') as af:
                res = openai.Audio.transcriptions.create(model='whisper-1', file=af)  # type: ignore
            return getattr(res, 'text', '') or (res.get('text') if isinstance(res, dict) else '')
        except Exception as e:
            raise RuntimeError(f"è°ƒç”¨è¯­éŸ³è¯†åˆ«å¤±è´¥: {e}")

# =============================================================================
# é…ç½®å’Œåˆå§‹åŒ–
# =============================================================================

# è®¾ç½®OpenAI API Key
os.environ["OPENAI_API_KEY"] = "Your openai-api-key"

# åˆ›å»ºFlaskåº”ç”¨
app = Flask(__name__)
app.secret_key = 'your-secret-key-here'

# åº”ç”¨é…ç½®
UPLOAD_FOLDER = 'uploads'
ALLOWED_EXTENSIONS = {
    'pdf', 'txt', 'doc', 'docx', 'py', 'js', 'java', 'cpp', 'c', 
    'csv', 'xlsx', 'xls', 'md', 'json',
    # éŸ³é¢‘
    'mp3', 'wav', 'm4a', 'webm', 'ogg'
}
app.config['UPLOAD_FOLDER'] = UPLOAD_FOLDER
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB

# ç¡®ä¿ä¸Šä¼ ç›®å½•å­˜åœ¨
os.makedirs(UPLOAD_FOLDER, exist_ok=True)

# å…¨å±€å˜é‡å­˜å‚¨å¯¹è¯å†å²å’Œæ–‡ä»¶ä¿¡æ¯
conversation_history: Dict[str, List[Dict[str, Any]]] = {}
uploaded_files: Dict[str, Dict[str, Any]] = {}
# MCP æ³¨å†Œè¡¨ï¼ˆæŒä¹…åŒ–åˆ°æœ¬åœ°JSONï¼‰
mcp_registry: Dict[str, Dict[str, Any]] = {}
# ä½¿ç”¨å½“å‰æ–‡ä»¶æ‰€åœ¨ç›®å½•ä½œä¸ºåŸºå‡†ï¼Œé¿å…å·¥ä½œç›®å½•å˜åŒ–å¯¼è‡´ä¿å­˜ä½ç½®ä¸ä¸€è‡´
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.path.join(BASE_DIR, 'data')
MCP_REGISTRY_FILE = os.path.join(DATA_DIR, 'mcps.json')
CONVERSATIONS_FILE = os.path.join(DATA_DIR, 'conversations.json')

def _ensure_data_dir(): 
    try:
        os.makedirs(DATA_DIR, exist_ok=True)
    except Exception:
        pass

def _load_mcp_registry():
    global mcp_registry
    _ensure_data_dir()
    if os.path.exists(MCP_REGISTRY_FILE):
        try:
            with open(MCP_REGISTRY_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, dict):
                    mcp_registry = data
        except Exception:
            mcp_registry = {}

def _save_mcp_registry():
    _ensure_data_dir()
    try:
        with open(MCP_REGISTRY_FILE, 'w', encoding='utf-8') as f:
            json.dump(mcp_registry, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ä¿å­˜MCPæ³¨å†Œè¡¨å¤±è´¥: {e}")


# ------------------ ä¼šè¯æŒä¹…åŒ– ------------------
def _load_conversations():
    global conversation_history
    _ensure_data_dir()
    if os.path.exists(CONVERSATIONS_FILE):
        try:
            with open(CONVERSATIONS_FILE, 'r', encoding='utf-8') as f:
                data = json.load(f)
                if isinstance(data, dict):
                    conversation_history = data
        except Exception:
            conversation_history = {}

def _save_conversations():
    _ensure_data_dir()
    try:
        trimmed = {}
        for conv_id, msgs in conversation_history.items():
            if isinstance(msgs, list):
                trimmed[conv_id] = msgs[-10:]
        with open(CONVERSATIONS_FILE, 'w', encoding='utf-8') as f:
            json.dump(trimmed, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"ä¿å­˜å¯¹è¯å¤±è´¥: {e}")


# =============================================================================
# AIWebApp ä¸»ç±»
# =============================================================================

class AIWebApp:
    """AIå…¨èƒ½æ•™å¸ˆWebåº”ç”¨ä¸»ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–AIåº”ç”¨"""
        self.processed_files = set()  # è·Ÿè¸ªå·²å¤„ç†çš„æ–‡ä»¶
        self.setup_agents()
    
    def create_common_tools(self) -> List[Any]:
        """åˆ›å»ºé€šç”¨å·¥å…·é›†"""
        tools = []
        
        # WebSearchTool - ç½‘ç»œæœç´¢å·¥å…·
        try:
            web_search_tool = WebSearchTool()
            tools.append(web_search_tool)
            print("âœ“ WebSearchTool åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            print(f"WebSearchTool åˆå§‹åŒ–å¤±è´¥: {e}")
        
        # ImageGenerationTool - å›¾åƒç”Ÿæˆå·¥å…·
        # æ ¹æ®å®˜æ–¹æ–‡æ¡£ï¼Œå°è¯•ä¸åŒçš„é…ç½®æ–¹å¼
        try:
            # æ–¹å¼2ï¼šå¸¦é…ç½®åˆå§‹åŒ–
            image_gen_tool = ImageGenerationTool({'type': 'image_generation'})
            tools.append(image_gen_tool)
            print("âœ“ ImageGenerationTool åˆå§‹åŒ–æˆåŠŸï¼ˆå¸¦é…ç½®ï¼‰")
        except Exception as e2:
            print(f"ImageGenerationTool å¸¦é…ç½®åˆå§‹åŒ–å¤±è´¥: {e2}")
        
        print(f"æ€»å…±åˆå§‹åŒ–äº† {len(tools)} ä¸ªå·¥å…·")
        return tools
    
    def read_file_content(self, file_path: str) -> str:
        """è¯»å–æ–‡ä»¶å†…å®¹"""
        try:
            file_extension = os.path.splitext(file_path)[1].lower()
            
            if file_extension in ['.txt', '.md', '.py', '.js', '.html', '.css', '.json', '.xml', '.csv']:
                # æ–‡æœ¬æ–‡ä»¶
                with open(file_path, 'r', encoding='utf-8') as f:
                    return f.read()
            elif file_extension in ['.pdf']:
                # PDFæ–‡ä»¶ - éœ€è¦å®‰è£…PyPDF2
                try:
                    import PyPDF2
                    with open(file_path, 'rb') as f:
                        reader = PyPDF2.PdfReader(f)
                        text = ""
                        for page in reader.pages:
                            text += page.extract_text() + "\n"
                        return text
                except ImportError:
                    return "PDFæ–‡ä»¶è¯»å–éœ€è¦å®‰è£…PyPDF2åº“: pip install PyPDF2"
                except Exception as e:
                    return f"PDFæ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}"
            elif file_extension in ['.docx']:
                # Wordæ–‡æ¡£ - éœ€è¦å®‰è£…python-docx
                try:
                    from docx import Document
                    doc = Document(file_path)
                    text = ""
                    for paragraph in doc.paragraphs:
                        text += paragraph.text + "\n"
                    return text
                except ImportError:
                    return "Wordæ–‡æ¡£è¯»å–éœ€è¦å®‰è£…python-docxåº“: pip install python-docx"
                except Exception as e:
                    return f"Wordæ–‡æ¡£è¯»å–å¤±è´¥: {str(e)}"
            else:
                return f"ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹: {file_extension}"
                
        except Exception as e:
            return f"è¯»å–æ–‡ä»¶æ—¶å‡ºé”™: {str(e)}"
    
    def setup_agents(self) -> None:
        """è®¾ç½®æ™ºèƒ½ä½“ç³»ç»Ÿ"""
        # åˆ›å»ºé€šç”¨å·¥å…·é›†
        self.common_tools = self.create_common_tools()
        
        # æ•°å­¦æ•™å¸ˆæ™ºèƒ½ä½“
        self.math_teacher_agent = Agent(
            name="math teacher",
            instructions="""You are a professional mathematics teacher who can answer all user inquiries about mathematical topics in very detailed and highly accurate ways.

You have access to these tools:
- WebSearchTool: Search for latest mathematical concepts, formulas, or examples
- ImageGenerationTool: Create mathematical diagrams, graphs, or visual explanations

å·¥å…·ä½¿ç”¨è§„åˆ™ï¼š
- å½“ç”¨æˆ·è¦æ±‚ç”»å›¾ã€ç»˜åˆ¶å‡½æ•°å›¾åƒã€å‡ ä½•å›¾å½¢ã€æ•°å­¦å›¾è¡¨æ—¶ï¼ŒMUSTä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦æœ€æ–°çš„æ•°å­¦å…¬å¼ã€å®šç†ã€æˆ–æ•°å­¦åº”ç”¨å®ä¾‹æ—¶ï¼ŒMUSTä½¿ç”¨WebSearchTool
- å½“éœ€è¦å¯è§†åŒ–æ•°å­¦æ¦‚å¿µã€å‡½æ•°å…³ç³»ã€å‡ ä½•å›¾å½¢æ—¶ï¼ŒMUSTä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦æœç´¢æ•°å­¦å†å²ã€æ•°å­¦å®¶ä¿¡æ¯ã€æ•°å­¦åº”ç”¨æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨WebSearchTool

IMPORTANT: Always use tools when they would enhance your answer. Visual representations are crucial for mathematical understanding.""",
            handoff_description="You are an intelligent agent specializing in mathematical knowledge.",
            tools=self.common_tools
        )
        
        # ä¸­æ–‡æ•™å¸ˆæ™ºèƒ½ä½“
        self.chinese_teacher_agent = Agent(
            name="chinese teacher",
            instructions="""You are a professional Chinese language teacher who can answer all user inquiries about Chinese-language topics in very detailed and highly accurate ways.

You have access to various tools to enhance your teaching:
- WebSearchTool: Search for Chinese literature, poetry, idioms, or cultural context
- ImageGenerationTool: Create visual aids for Chinese characters, calligraphy, or cultural scenes

å·¥å…·ä½¿ç”¨è§„åˆ™ï¼š
- å½“éœ€è¦æœç´¢ä¸­å›½æ–‡å­¦ã€å¤è¯—è¯ã€æˆè¯­å…¸æ•…ã€æ–‡åŒ–èƒŒæ™¯æ—¶ï¼ŒMUSTä½¿ç”¨WebSearchTool
- å½“éœ€è¦å±•ç¤ºæ±‰å­—ä¹¦å†™ã€ä¹¦æ³•ä½œå“ã€æ–‡åŒ–åœºæ™¯æ—¶ï¼ŒMUSTä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦æŸ¥æ‰¾å¤è¯—è¯çš„è¯¦ç»†è§£é‡Šã€ä½œè€…èƒŒæ™¯ã€å†å²èƒŒæ™¯æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨WebSearchTool
- å½“éœ€è¦å¯è§†åŒ–æ±‰å­—ç»“æ„ã€ç¬”ç”»é¡ºåºã€æ–‡åŒ–åœºæ™¯æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨ImageGenerationTool

Use these tools when they would help provide better explanations or more comprehensive answers.""",
            handoff_description="You are an intelligent agent specializing in Chinese language knowledge.",
            tools=self.common_tools
        )
        
        # ç‰©ç†æ•™å¸ˆæ™ºèƒ½ä½“
        self.physics_teacher_agent = Agent(
            name="physics teacher",
            instructions="""You are a professional physics teacher who can answer all user inquiries about physics in very detailed and highly accurate ways.

You have access to various tools to enhance your teaching:
- WebSearchTool: Search for latest physics research, experiments, or real-world applications
- ImageGenerationTool: Create physics diagrams, force diagrams, wave patterns, or experimental setups

å·¥å…·ä½¿ç”¨è§„åˆ™ï¼š
- å½“éœ€è¦æœç´¢æœ€æ–°ç‰©ç†ç ”ç©¶ã€å®éªŒæ•°æ®ã€ç‰©ç†åº”ç”¨å®ä¾‹æ—¶ï¼ŒMUSTä½¿ç”¨WebSearchTool
- å½“éœ€è¦ç»˜åˆ¶ç‰©ç†å›¾è¡¨ã€å—åŠ›å›¾ã€æ³¢å½¢å›¾ã€å®éªŒè£…ç½®å›¾æ—¶ï¼ŒMUSTä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦å¯è§†åŒ–ç‰©ç†æ¦‚å¿µã€åŠ›åœºã€ç”µç£åœºã€æ³¢åŠ¨ç°è±¡æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦æŸ¥æ‰¾ç‰©ç†å…¬å¼ã€å¸¸æ•°ã€å®éªŒæ–¹æ³•æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨WebSearchTool

Use these tools when they would help provide better explanations or more comprehensive answers.""",
            handoff_description="You are an intelligent agent specializing in physics",
            tools=self.common_tools
        )
        
        # å†å²æ•™å¸ˆæ™ºèƒ½ä½“
        self.history_teacher_agent = Agent(
            name="historyer",
            instructions="""You are a professional history teacher who can answer all user inquiries about history in very detailed and highly accurate ways.

You have access to various tools to enhance your teaching:
- WebSearchTool: Search for historical facts, timelines, or recent historical discoveries
- ImageGenerationTool: Create historical maps, timelines, or visual representations of historical events

å·¥å…·ä½¿ç”¨è§„åˆ™ï¼š
- å½“éœ€è¦æœç´¢å†å²äº‹å®ã€æ—¶é—´çº¿ã€æœ€æ–°å†å²å‘ç°æ—¶ï¼ŒMUSTä½¿ç”¨WebSearchTool
- å½“éœ€è¦åˆ›å»ºå†å²åœ°å›¾ã€æ—¶é—´çº¿ã€å†å²äº‹ä»¶å¯è§†åŒ–æ—¶ï¼ŒMUSTä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦å±•ç¤ºå†å²äººç‰©ã€å†å²å»ºç­‘ã€å†å²åœºæ™¯æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦æŸ¥æ‰¾å†å²ç»†èŠ‚ã€å†å²èƒŒæ™¯ã€å†å²å½±å“æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨WebSearchTool

Use these tools when they would help provide better explanations or more comprehensive answers.""",
            handoff_description="You are an intelligent agent specializing in history",
            tools=self.common_tools
        )
        
        # æ–‡ä»¶åˆ†ææ™ºèƒ½ä½“ - ä¸“é—¨å¤„ç†æ–‡ä»¶ç›¸å…³çš„é—®é¢˜
        self.file_analysis_agent = Agent(
            name="file analysis agent",
            instructions="""ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ–‡ä»¶åˆ†ææ™ºèƒ½ä½“ï¼Œä¸“é—¨å¤„ç†ç”¨æˆ·ä¸Šä¼ çš„æ–‡ä»¶å†…å®¹ã€‚
            tools=self.common_tools

ä½ çš„ä¸»è¦èŒè´£ï¼š
1. åˆ†ææ–‡ä»¶å†…å®¹ï¼Œæå–å…³é”®ä¿¡æ¯
2. å›ç­”å…³äºæ–‡ä»¶å†…å®¹çš„é—®é¢˜
3. æ€»ç»“æ–‡ä»¶è¦ç‚¹
4. è§£é‡Šæ–‡ä»¶ä¸­çš„æ¦‚å¿µå’Œå†…å®¹
5. æ ¹æ®æ–‡ä»¶å†…å®¹æä¾›å»ºè®®æˆ–è§£ç­”

ä½ æ‹¥æœ‰å„ç§å·¥å…·æ¥å¢å¼ºä½ çš„åˆ†æèƒ½åŠ›ï¼š
- WebSearchTool: æœç´¢ç›¸å…³ä¿¡æ¯æ¥è¡¥å……æ–‡ä»¶å†…å®¹
- ImageGenerationTool: åˆ›å»ºå›¾è¡¨ã€æµç¨‹å›¾æ¥å¯è§†åŒ–æ–‡ä»¶å†…å®¹

å·¥å…·ä½¿ç”¨è§„åˆ™ï¼š
- å½“æ–‡ä»¶å†…å®¹æ¶‰åŠéœ€è¦æœ€æ–°ä¿¡æ¯éªŒè¯æˆ–è¡¥å……æ—¶ï¼ŒMUSTä½¿ç”¨WebSearchTool
- å½“éœ€è¦å°†æ–‡ä»¶å†…å®¹å¯è§†åŒ–ã€åˆ›å»ºæµç¨‹å›¾ã€æ¦‚å¿µå›¾æ—¶ï¼ŒMUSTä½¿ç”¨ImageGenerationTool
- å½“æ–‡ä»¶å†…å®¹æ¶‰åŠå¤æ‚æ¦‚å¿µéœ€è¦å›¾è¡¨è¯´æ˜æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦æœç´¢æ–‡ä»¶å†…å®¹ç›¸å…³çš„èƒŒæ™¯ä¿¡æ¯ã€å®šä¹‰ã€è§£é‡Šæ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨WebSearchTool

è¯·ä»”ç»†åˆ†æç”¨æˆ·æä¾›çš„æ–‡ä»¶å†…å®¹ï¼Œå¹¶åŸºäºæ–‡ä»¶å†…å®¹å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚å¦‚æœéœ€è¦æ›´å¤šä¿¡æ¯ï¼Œå¯ä»¥ä½¿ç”¨å·¥å…·è¿›è¡Œæœç´¢ã€‚""",
            handoff_description="You are an intelligent agent specializing in file content analysis.",
            tools=self.common_tools
        )
        
        # é€šç”¨é—®é¢˜æ™ºèƒ½ä½“
        self.general_agent = Agent(
            name="general question agent",
            instructions="""ä½ æ˜¯ä¸€ä¸ªé€šç”¨é—®é¢˜å›ç­”åŠ©æ‰‹ï¼Œä¸“é—¨å¤„ç†ä»¥ä¸‹ç±»å‹çš„é—®é¢˜ï¼š
1. å¯¹è¯å†å²ç›¸å…³é—®é¢˜ï¼ˆå¦‚"æˆ‘é—®ä½ çš„ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ä»€ä¹ˆï¼Ÿ"ã€"æˆ‘ä»¬åˆšæ‰èŠäº†ä»€ä¹ˆï¼Ÿ"ï¼‰
2. ç³»ç»ŸåŠŸèƒ½ç›¸å…³é—®é¢˜
3. æ—¶é—´ã€æ—¥æœŸã€å¤©æ°”ã€æ–°é—»ç­‰å®æ—¶ä¿¡æ¯é—®é¢˜
4. ä¸ç¬¦åˆå…¶ä»–ä¸“ä¸šé¢†åŸŸçš„é—®é¢˜
5. éœ€è¦ç»¼åˆå¤šä¸ªé¢†åŸŸçŸ¥è¯†çš„é—®é¢˜

ä½ æ‹¥æœ‰å„ç§å·¥å…·æ¥å¢å¼ºä½ çš„å›ç­”èƒ½åŠ›ï¼š
- WebSearchTool: æœç´¢æœ€æ–°ä¿¡æ¯ã€äº‹å®æˆ–æ•°æ®
- ImageGenerationTool: åˆ›å»ºå›¾è¡¨ã€æµç¨‹å›¾æˆ–è§†è§‰è¯´æ˜

å·¥å…·ä½¿ç”¨è§„åˆ™ï¼š
- å½“ç”¨æˆ·è¯¢é—®æ—¶é—´ã€æ—¥æœŸã€å¤©æ°”ã€æ–°é—»ã€è‚¡ç¥¨ä»·æ ¼ç­‰å®æ—¶ä¿¡æ¯æ—¶ï¼ŒMUSTä½¿ç”¨WebSearchTool
- å½“ç”¨æˆ·è¯¢é—®éœ€è¦è§†è§‰åŒ–å±•ç¤ºçš„å†…å®¹æ—¶ï¼ŒMUSTä½¿ç”¨ImageGenerationTool
- å½“éœ€è¦æœ€æ–°æ•°æ®ã€äº‹å®æˆ–ä¿¡æ¯æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨WebSearchTool
- å½“éœ€è¦åˆ›å»ºå›¾è¡¨ã€æµç¨‹å›¾ã€æ¦‚å¿µå›¾æ—¶ï¼Œä¸»åŠ¨ä½¿ç”¨ImageGenerationTool

è¯·åŸºäºå¯¹è¯å†å²æ¥å›ç­”ç”¨æˆ·çš„é—®é¢˜ï¼Œå¦‚æœæ¶‰åŠä¹‹å‰çš„å†…å®¹ï¼Œè¯·å‡†ç¡®å›å¿†å¹¶å›ç­”ã€‚å½“å·¥å…·èƒ½å¸®åŠ©æä¾›æ›´å¥½çš„ç­”æ¡ˆæ—¶ï¼Œè¯·ä¸»åŠ¨ä½¿ç”¨è¿™äº›å·¥å…·ã€‚""",
            handoff_description="You are an intelligent agent specializing in general questions and conversation context.",
            tools=self.common_tools
        )
        
        # Triage Agent - æ™ºèƒ½ä½“é€‰æ‹©å™¨
        self.triage_agent = Agent(
            name="Triage Agent",
            instructions="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä½“é€‰æ‹©å™¨ã€‚æ ¹æ®ç”¨æˆ·é—®é¢˜å’Œå¯¹è¯å†å²é€‰æ‹©æœ€åˆé€‚çš„æ™ºèƒ½ä½“ï¼š

- math_teacher_agent: æ•°å­¦ã€æ–¹ç¨‹ã€è®¡ç®—ã€ä»£æ•°ã€å‡ ä½•ã€å›¾åƒã€å‡½æ•°ç­‰
- chinese_teacher_agent: ä¸­æ–‡ã€æ–‡å­¦ã€è¯—æ­Œã€æˆè¯­ã€è¯­æ³•ç­‰  
- physics_teacher_agent: ç‰©ç†ã€åŠ›å­¦ã€è¿åŠ¨å®šå¾‹ã€èƒ½é‡ç­‰
- history_teacher_agent: å†å²ã€å†å²äº‹ä»¶ã€å¤ä»£æ–‡æ˜ç­‰
- file_analysis_agent: æ–‡ä»¶åˆ†æã€æ–‡ä»¶å†…å®¹ç›¸å…³é—®é¢˜ã€ç”¨æˆ·æ˜ç¡®è¦æ±‚åˆ†ææ–‡ä»¶
- general_agent: å¯¹è¯å†å²ã€ç³»ç»ŸåŠŸèƒ½ã€ç»¼åˆé—®é¢˜ã€æ—¶é—´æ—¥æœŸã€å…¶ä»–ä¸ç¬¦åˆä¸Šè¿°åˆ†ç±»çš„é—®é¢˜

é‡è¦ï¼šä½ çš„å›ç­”å¿…é¡»åªåŒ…å«ä¸€ä¸ªæ™ºèƒ½ä½“åç§°ï¼Œä¸è¦ä»»ä½•è§£é‡Šã€æè¿°æˆ–å…¶ä»–å†…å®¹ã€‚

é€‰æ‹©è§„åˆ™ï¼ˆæŒ‰ä¼˜å…ˆçº§ï¼‰ï¼š
1. å¦‚æœç”¨æˆ·æ˜ç¡®è¦æ±‚åˆ†ææ–‡ä»¶å†…å®¹ï¼ˆå¦‚"åˆ†æè¿™ä¸ªæ–‡ä»¶"ã€"æ€»ç»“æ–‡ä»¶å†…å®¹"ï¼‰ï¼Œé€‰æ‹© file_analysis_agent
2. å¦‚æœé—®é¢˜æ¶‰åŠæ—¶é—´ã€æ—¥æœŸã€å½“å‰ä¿¡æ¯ã€å®æ—¶æ•°æ®ï¼Œé€‰æ‹© general_agentï¼ˆå› ä¸ºå®ƒæœ‰ç½‘ç»œæœç´¢èƒ½åŠ›ï¼‰
3. å¦‚æœé—®é¢˜æ¶‰åŠæ•°å­¦æ¦‚å¿µï¼Œé€‰æ‹© math_teacher_agent
4. å¦‚æœé—®é¢˜æ¶‰åŠä¸­æ–‡ã€æ–‡å­¦ï¼Œé€‰æ‹© chinese_teacher_agent
5. å¦‚æœé—®é¢˜æ¶‰åŠç‰©ç†æ¦‚å¿µï¼Œé€‰æ‹© physics_teacher_agent
6. å¦‚æœé—®é¢˜æ¶‰åŠå†å²ï¼Œé€‰æ‹© history_teacher_agent
7. å…¶ä»–æƒ…å†µé€‰æ‹© general_agent

ç‰¹åˆ«æ³¨æ„ï¼š
- è¯­éŸ³è½¬å†™åçš„æ–‡æœ¬å†…å®¹æŒ‰æ–‡æœ¬å†…å®¹åˆ¤æ–­ï¼Œä¸æŒ‰æ–‡ä»¶ç±»å‹åˆ¤æ–­
- æ—¶é—´ã€æ—¥æœŸã€å¤©æ°”ã€æ–°é—»ç­‰å®æ—¶ä¿¡æ¯é—®é¢˜é€‰æ‹© general_agent
- åªæœ‰æ˜ç¡®è¦æ±‚åˆ†ææ–‡ä»¶å†…å®¹æ—¶æ‰é€‰æ‹© file_analysis_agent

ä¾‹å¦‚ï¼š
- ç”¨æˆ·é—®"ä»Šå¤©çš„æ—¥æœŸå’Œç°åœ¨åŒ—äº¬çš„æ—¶é—´" â†’ å›ç­”ï¼šgeneral_agent
- ç”¨æˆ·é—®"ç”»ä¸€ä¸ªäºŒæ¬¡å‡½æ•°å›¾åƒ" â†’ å›ç­”ï¼šmath_teacher_agent
- ç”¨æˆ·é—®"ä»€ä¹ˆæ˜¯è¯—æ­Œ" â†’ å›ç­”ï¼šchinese_teacher_agent
- ç”¨æˆ·é—®"åˆ†æè¿™ä¸ªPDFæ–‡ä»¶çš„å†…å®¹" â†’ å›ç­”ï¼šfile_analysis_agent
- ç”¨æˆ·é—®"æˆ‘é—®çš„ç¬¬ä¸€ä¸ªé—®é¢˜æ˜¯ä»€ä¹ˆ" â†’ å›ç­”ï¼šgeneral_agent

åªè¿”å›æ™ºèƒ½ä½“åç§°ï¼Œä¸è¦å…¶ä»–ä»»ä½•æ–‡å­—ã€‚""",
            handoffs=[
                "math_teacher_agent", "chinese_teacher_agent", 
                "physics_teacher_agent", "history_teacher_agent", 
                "file_analysis_agent", "general_agent"
            ],
            tools=[]  # Triage Agent ä¸éœ€è¦å·¥å…·ï¼Œåªåšé€‰æ‹©
        )
    
    def build_context_prompt(self, history: List[Dict[str, Any]], current_question: str) -> str:
        """æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æç¤º"""
        if not history or len(history) <= 1:
            return current_question
        
        context_parts = ["ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„å¯¹è¯å†å²ï¼š"]
        
        # è·Ÿè¸ªåœ¨å½“å‰å¯¹è¯ä¸­å·²å¤„ç†çš„æ–‡ä»¶
        current_processed_files = set()
        
        # åªå–æœ€è¿‘8è½®å¯¹è¯ï¼Œé¿å…tokenè¿‡å¤š
        recent_history = history[-8:]
        for msg in recent_history:
            role = "ç”¨æˆ·" if msg['type'] == 'user' else "AIåŠ©æ‰‹"
            message_text = msg['message']
            
            # å¦‚æœæ¶ˆæ¯åŒ…å«æ–‡ä»¶ä¿¡æ¯ï¼Œæ·»åŠ æ–‡ä»¶ä¸Šä¸‹æ–‡
            if msg['type'] == 'user' and 'file_id' in msg:
                file_id = msg['file_id']
                print(f"ğŸ” æ£€æµ‹åˆ°æ–‡ä»¶ID: {file_id}")
                # ä½¿ç”¨å…¨å±€å˜é‡
                global uploaded_files
                print(f"ğŸ“ å½“å‰ä¸Šä¼ çš„æ–‡ä»¶: {list(uploaded_files.keys())}")
                # è‹¥æ˜¯è¯­éŸ³ä¸”å·²ç»åœ¨ /api/chat ä¸­è‡ªåŠ¨è½¬å†™ï¼Œåˆ™ç›´æ¥ä½¿ç”¨è½¬å†™æ–‡æœ¬ï¼Œé¿å…å†æ¬¡è¯»å–åŸéŸ³é¢‘
                if msg.get('transcribed_from_audio'):
                    file_info = uploaded_files.get(file_id, {})
                    file_name = file_info.get('name', 'audio')
                    trans_text = msg.get('transcribed_text') or message_text
                    context_parts.append(f"{role}: [ä¸Šä¼ äº†è¯­éŸ³ '{file_name}' å¹¶å·²è‡ªåŠ¨è½¬å†™]")
                    context_parts.append(f"è½¬å†™æ–‡æœ¬ï¼š\n{trans_text}")
                    context_parts.append(f"{role}: {message_text}")
                elif file_id in uploaded_files and file_id not in current_processed_files:
                    file_info = uploaded_files[file_id]
                    file_path = file_info['path']
                    file_name = file_info['name']
                    print(f"ğŸ“„ è¯»å–æ–‡ä»¶: {file_name}")
                    file_content = self.read_file_content(file_path)
                    print(f"ğŸ“„ æ–‡ä»¶å†…å®¹é•¿åº¦: {len(file_content)} å­—ç¬¦")
                    
                    # å°†æ–‡ä»¶å†…å®¹æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼ˆåªæ·»åŠ ä¸€æ¬¡ï¼‰
                    context_parts.append(f"{role}: [ä¸Šä¼ äº†æ–‡ä»¶ '{file_name}']")
                    context_parts.append(f"æ–‡ä»¶å†…å®¹ï¼š\n{file_content}")
                    current_processed_files.add(file_id)
                    context_parts.append(f"{role}: {message_text}")
                elif file_id in uploaded_files and file_id in current_processed_files:
                    # æ–‡ä»¶åœ¨å½“å‰å¯¹è¯ä¸­å·²å¤„ç†è¿‡ï¼Œåªæ·»åŠ å¼•ç”¨
                    file_info = uploaded_files[file_id]
                    file_name = file_info['name']
                    print(f"ğŸ“„ æ–‡ä»¶å·²å¤„ç†è¿‡ï¼Œåªæ·»åŠ å¼•ç”¨: {file_name}")
                    context_parts.append(f"{role}: [ç»§ç»­è®¨è®ºæ–‡ä»¶ '{file_name}']")
                    context_parts.append(f"{role}: {message_text}")
                else:
                    print(f"âŒ æ–‡ä»¶ID {file_id} æœªæ‰¾åˆ°")
                    context_parts.append(f"{role}: {message_text}")
            else:
                context_parts.append(f"{role}: {message_text}")
        
        context_parts.extend([
            f"\nå½“å‰é—®é¢˜ï¼š{current_question}",
            "\nè¯·åŸºäºä»¥ä¸Šå¯¹è¯å†å²å›ç­”å½“å‰é—®é¢˜ã€‚"
        ])
        
        return "\n".join(context_parts)
    
    def build_simple_context_prompt(self, history: List[Dict[str, Any]], current_question: str) -> str:
        """æ„å»ºç®€åŒ–çš„ä¸Šä¸‹æ–‡æç¤ºï¼ˆä¸åŒ…å«æ–‡ä»¶å†…å®¹ï¼Œåªç»™ Triage Agent ç”¨ï¼‰"""
        if not history or len(history) <= 1:
            return current_question
        
        context_parts = ["ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„å¯¹è¯å†å²ï¼š"]
        
        # åªå–æœ€è¿‘8è½®å¯¹è¯ï¼Œé¿å…tokenè¿‡å¤š
        recent_history = history[-8:]
        for msg in recent_history:
            role = "ç”¨æˆ·" if msg['type'] == 'user' else "AIåŠ©æ‰‹"
            message_text = msg['message']
            
            # å¦‚æœæ¶ˆæ¯åŒ…å«æ–‡ä»¶ä¿¡æ¯ï¼Œåªæ·»åŠ æ–‡ä»¶å¼•ç”¨ï¼Œä¸è¯»å–å†…å®¹
            if msg['type'] == 'user' and 'file_id' in msg:
                file_id = msg['file_id']
                global uploaded_files
                if file_id in uploaded_files:
                    file_info = uploaded_files[file_id]
                    file_name = file_info['name']
                    context_parts.append(f"{role}: [ä¸Šä¼ äº†æ–‡ä»¶ '{file_name}']")
                    context_parts.append(f"{role}: {message_text}")
                else:
                    context_parts.append(f"{role}: {message_text}")
            else:
                context_parts.append(f"{role}: {message_text}")
        
        context_parts.extend([
            f"\nå½“å‰é—®é¢˜ï¼š{current_question}",
            "\nè¯·åŸºäºä»¥ä¸Šå¯¹è¯å†å²å›ç­”å½“å‰é—®é¢˜ã€‚"
        ])
        
        return "\n".join(context_parts)
    
    def build_file_analysis_prompt(self, history: List[Dict[str, Any]], current_question: str, file_id: str = None) -> str:
        """ä¸ºæ–‡ä»¶åˆ†ææ™ºèƒ½ä½“æ„å»ºåŒ…å«æ–‡ä»¶å†…å®¹çš„æç¤º"""
        context_parts = ["ä»¥ä¸‹æ˜¯æˆ‘ä»¬çš„å¯¹è¯å†å²ï¼š"]
        
        # è·Ÿè¸ªåœ¨å½“å‰å¯¹è¯ä¸­å·²å¤„ç†çš„æ–‡ä»¶
        current_processed_files = set()
        
        # åªå–æœ€è¿‘8è½®å¯¹è¯ï¼Œé¿å…tokenè¿‡å¤š
        recent_history = history[-8:]
        for msg in recent_history:
            role = "ç”¨æˆ·" if msg['type'] == 'user' else "AIåŠ©æ‰‹"
            message_text = msg['message']
            
            # å¦‚æœæ¶ˆæ¯åŒ…å«æ–‡ä»¶ä¿¡æ¯ï¼Œæ·»åŠ æ–‡ä»¶ä¸Šä¸‹æ–‡
            if msg['type'] == 'user' and 'file_id' in msg:
                file_id = msg['file_id']
                print(f"ğŸ” æ–‡ä»¶åˆ†ææ™ºèƒ½ä½“æ£€æµ‹åˆ°æ–‡ä»¶ID: {file_id}")
                
                # ä½¿ç”¨å…¨å±€å˜é‡
                global uploaded_files
                if msg.get('transcribed_from_audio'):
                    file_info = uploaded_files.get(file_id, {})
                    file_name = file_info.get('name', 'audio')
                    trans_text = msg.get('transcribed_text') or message_text
                    context_parts.append(f"{role}: [ä¸Šä¼ äº†è¯­éŸ³ '{file_name}' å¹¶å·²è‡ªåŠ¨è½¬å†™]")
                    context_parts.append(f"è½¬å†™æ–‡æœ¬ï¼š\n{trans_text}")
                    context_parts.append(f"{role}: {message_text}")
                elif file_id in uploaded_files and file_id not in current_processed_files:
                    file_info = uploaded_files[file_id]
                    file_path = file_info['path']
                    file_name = file_info['name']
                    print(f"ğŸ“„ æ–‡ä»¶åˆ†ææ™ºèƒ½ä½“è¯»å–æ–‡ä»¶: {file_name}")
                    file_content = self.read_file_content(file_path)
                    print(f"ğŸ“„ æ–‡ä»¶å†…å®¹é•¿åº¦: {len(file_content)} å­—ç¬¦")
                    
                    # å°†æ–‡ä»¶å†…å®¹æ·»åŠ åˆ°ä¸Šä¸‹æ–‡ä¸­ï¼ˆåªæ·»åŠ ä¸€æ¬¡ï¼‰
                    context_parts.append(f"{role}: [ä¸Šä¼ äº†æ–‡ä»¶ '{file_name}']")
                    context_parts.append(f"æ–‡ä»¶å†…å®¹ï¼š\n{file_content}")
                    current_processed_files.add(file_id)
                    context_parts.append(f"{role}: {message_text}")
                elif file_id in uploaded_files and file_id in current_processed_files:
                    # æ–‡ä»¶åœ¨å½“å‰å¯¹è¯ä¸­å·²å¤„ç†è¿‡ï¼Œåªæ·»åŠ å¼•ç”¨
                    file_info = uploaded_files[file_id]
                    file_name = file_info['name']
                    print(f"ğŸ“„ æ–‡ä»¶åˆ†ææ™ºèƒ½ä½“æ–‡ä»¶å·²å¤„ç†è¿‡ï¼Œåªæ·»åŠ å¼•ç”¨: {file_name}")
                    context_parts.append(f"{role}: [ç»§ç»­è®¨è®ºæ–‡ä»¶ '{file_name}']")
                    context_parts.append(f"{role}: {message_text}")
                else:
                    print(f"âŒ æ–‡ä»¶ID {file_id} æœªæ‰¾åˆ°")
                    context_parts.append(f"{role}: {message_text}")
            else:
                context_parts.append(f"{role}: {message_text}")
        
        context_parts.extend([
            f"\nå½“å‰é—®é¢˜ï¼š{current_question}",
            "\nè¯·åŸºäºä»¥ä¸Šå¯¹è¯å†å²å’Œæ–‡ä»¶å†…å®¹å›ç­”å½“å‰é—®é¢˜ã€‚"
        ])
        
        return "\n".join(context_parts)
    
    async def process_user_question(self, user_message: str, conversation_id: str, file_id: str = None) -> Dict[str, str]:
        """å¤„ç†ç”¨æˆ·é—®é¢˜ - ä¸­å¿ƒæ™ºèƒ½ä½“åˆ¤æ–­å¹¶è°ƒç”¨å¯¹åº”ä¸“ä¸šæ™ºèƒ½ä½“"""
        try:
            # 1. è·å–å¯¹è¯å†å²
            history = conversation_history.get(conversation_id, [])
            
            # 2. æ„å»ºç®€åŒ–çš„æç¤ºç»™ Triage Agentï¼ˆä¸éœ€è¦æ–‡ä»¶å†…å®¹ï¼‰
            context_prompt = self.build_simple_context_prompt(history, user_message)
            
            # 3. ä½¿ç”¨ Triage Agent åˆ¤æ–­éœ€è¦è°ƒç”¨å“ªä¸ªæ™ºèƒ½ä½“
            triage_result = await Runner.run(self.triage_agent, context_prompt)
            
            # è°ƒè¯•ä¿¡æ¯
            print(f"Triage Agent è¾“å‡º: {triage_result.final_output}")
            
            # 4. ä»ç»“æœä¸­æå–é€‰æ‹©çš„æ™ºèƒ½ä½“åç§°
            selected_agent_name = self.extract_agent_name(triage_result.final_output)
            print(f"é€‰æ‹©çš„æ™ºèƒ½ä½“: {selected_agent_name}")
            
            # 5. æ„å»ºåŒ…å«ä¸Šä¸‹æ–‡çš„æç¤ºç»™é€‰ä¸­çš„æ™ºèƒ½ä½“
            if selected_agent_name == "file_analysis_agent":
                # æ–‡ä»¶åˆ†ææ™ºèƒ½ä½“ä½¿ç”¨ä¸“é—¨çš„æç¤ºæ„å»ºæ–¹æ³•
                agent_context_prompt = self.build_file_analysis_prompt(history, user_message, file_id)
            else:
                # å…¶ä»–æ™ºèƒ½ä½“ä½¿ç”¨é€šç”¨æç¤ºæ„å»ºæ–¹æ³•
                agent_context_prompt = self.build_context_prompt(history, user_message)
            
            # 6. æ ¹æ®é€‰æ‹©çš„æ™ºèƒ½ä½“åç§°è°ƒç”¨å¯¹åº”çš„ä¸“ä¸šæ™ºèƒ½ä½“
            agent_mapping = {
                "math_teacher_agent": (self.math_teacher_agent, "æ•°å­¦æ•™å¸ˆ"),
                "chinese_teacher_agent": (self.chinese_teacher_agent, "ä¸­æ–‡æ•™å¸ˆ"),
                "physics_teacher_agent": (self.physics_teacher_agent, "ç‰©ç†æ•™å¸ˆ"),
                "history_teacher_agent": (self.history_teacher_agent, "å†å²æ•™å¸ˆ"),
                "file_analysis_agent": (self.file_analysis_agent, "æ–‡ä»¶åˆ†æåŠ©æ‰‹"),
                "general_agent": (self.general_agent, "é€šç”¨åŠ©æ‰‹")
            }
            
            if selected_agent_name in agent_mapping:
                agent, display_name = agent_mapping[selected_agent_name]
                result = await Runner.run(agent, agent_context_prompt)
                agent_display_name = display_name
            else:
                # é»˜è®¤ä½¿ç”¨é€šç”¨æ™ºèƒ½ä½“
                result = await Runner.run(self.general_agent, agent_context_prompt)
                agent_display_name = "é€šç”¨åŠ©æ‰‹"
            
            # 7. æå–å·¥å…·è°ƒç”¨ä¿¡æ¯
            tools_used = self.extract_tools_used(result)
            
            # 8. æå–å›¾ç‰‡æ•°æ®
            images = self.extract_images(result)
            
            # 9. è¿”å›åŒ…å«æ™ºèƒ½ä½“åç§°ã€å·¥å…·ä¿¡æ¯å’Œå›¾ç‰‡çš„ç»“æœ
            return {
                'content': result.final_output,
                'agent_name': agent_display_name,
                'agent_id': selected_agent_name,
                'tools_used': tools_used,
                'images': images
            }
            
        except Exception as e:
            return {
                'content': f"å¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯ï¼š{str(e)}",
                'agent_name': "ç³»ç»Ÿé”™è¯¯",
                'agent_id': "error",
                'tools_used': []
            }
    
    def extract_agent_name(self, triage_output: str) -> str:
        """ä» Triage Agent çš„è¾“å‡ºä¸­æå–æ™ºèƒ½ä½“åç§°"""
        output_lower = triage_output.lower()
        
        # ä¼˜å…ˆæ£€æŸ¥å®Œæ•´çš„æ™ºèƒ½ä½“åç§°
        agent_names = [
            "general_agent", "chinese_teacher_agent", "physics_teacher_agent",
            "history_teacher_agent", "math_teacher_agent", "file_analysis_agent"
        ]
        
        for agent_name in agent_names:
            if agent_name in output_lower:
                return agent_name
        
        # ç„¶åæ£€æŸ¥å…³é”®è¯ï¼ˆæ›´ç²¾ç¡®çš„åŒ¹é…ï¼‰
        keyword_mapping = [
            ("general", "agent", "general_agent"),
            ("chinese", "teacher", "chinese_teacher_agent"),
            ("physics", "teacher", "physics_teacher_agent"),
            ("history", "teacher", "history_teacher_agent"),
            ("math", "teacher", "math_teacher_agent")
        ]
        
        for keyword1, keyword2, agent_name in keyword_mapping:
            if keyword1 in output_lower and keyword2 in output_lower:
                return agent_name
        
        # æœ€åæ£€æŸ¥å­¦ç§‘å…³é”®è¯
        subject_mapping = [
            ("ä¸­æ–‡", "è¯­æ–‡", "è¯­è¨€", "chinese_teacher_agent"),
            ("ç‰©ç†", "åŠ›å­¦", "ç‰›é¡¿", "physics_teacher_agent"),
            ("å†å²", "å¤ä»£", "æœä»£", "history_teacher_agent"),
            ("æ•°å­¦", "æ–¹ç¨‹", "è®¡ç®—", "math_teacher_agent")
        ]
        
        for keywords, agent_name in subject_mapping:
            if any(keyword in output_lower for keyword in keywords):
                return agent_name
        
        # é»˜è®¤è¿”å›é€šç”¨æ™ºèƒ½ä½“
        return "general_agent"
    
    def extract_tools_used(self, result) -> List[Dict[str, str]]:
        """ä»æ™ºèƒ½ä½“æ‰§è¡Œç»“æœä¸­æå–å·¥å…·è°ƒç”¨ä¿¡æ¯"""
        tools_used = []
        
        try:
            # æ£€æŸ¥ new_items å±æ€§ä¸­çš„ ToolCallItem
            if hasattr(result, 'new_items') and result.new_items:
                for item in result.new_items:
                    if 'ToolCallItem' in str(type(item)) and hasattr(item, 'raw_item'):
                        raw_item = item.raw_item
                        
                        # ä» type å±æ€§æ¨æ–­å·¥å…·ç±»å‹
                        if hasattr(raw_item, 'type'):
                            if 'image_generation' in str(raw_item.type):
                                tool_name = 'image_generation'
                                tool_info = {
                                    'name': tool_name,
                                    'display_name': self.get_tool_display_name(tool_name),
                                    'description': self.get_tool_description(tool_name)
                                }
                                tools_used.append(tool_info)
                            elif 'web_search' in str(raw_item.type):
                                tool_name = 'web_search'
                                tool_info = {
                                    'name': tool_name,
                                    'display_name': self.get_tool_display_name(tool_name),
                                    'description': self.get_tool_description(tool_name)
                                }
                                tools_used.append(tool_info)
            
            # æ˜¾ç¤ºå·¥å…·ä½¿ç”¨ä¿¡æ¯
            if tools_used:
                tool_names = [tool['display_name'] for tool in tools_used]
                print(f"ğŸ”§ ä½¿ç”¨çš„å·¥å…·: {', '.join(tool_names)}")
            
        except Exception as e:
            print(f"æå–å·¥å…·è°ƒç”¨ä¿¡æ¯æ—¶å‡ºé”™: {e}")
        
        return tools_used
    
    def extract_images(self, result) -> List[Dict[str, str]]:
        """ä»æ™ºèƒ½ä½“æ‰§è¡Œç»“æœä¸­æå–å›¾ç‰‡æ•°æ®"""
        images = []
        
        try:
            # æ£€æŸ¥ new_items å±æ€§ä¸­çš„å›¾ç‰‡ç”Ÿæˆç»“æœ
            if hasattr(result, 'new_items') and result.new_items:
                for item in result.new_items:
                    if 'ToolCallItem' in str(type(item)) and hasattr(item, 'raw_item'):
                        raw_item = item.raw_item
                        if hasattr(raw_item, 'type') and 'image_generation' in str(raw_item.type):
                            print(f"ğŸ–¼ï¸ å‘ç°å›¾åƒç”Ÿæˆç»“æœ")
                            
                            # æ£€æŸ¥å›¾ç‰‡æ•°æ®
                            if hasattr(raw_item, 'result') and raw_item.result:
                                # å›¾ç‰‡æ•°æ®å¯èƒ½æ˜¯URLæˆ–Base64
                                image_data = raw_item.result
                                print(f"å›¾ç‰‡æ•°æ®: {type(image_data)}")
                                print(f"å›¾ç‰‡æ•°æ®å†…å®¹: {image_data[:200]}...")  # æ˜¾ç¤ºå‰200ä¸ªå­—ç¬¦
                                
                                if isinstance(image_data, str):
                                    if image_data.startswith('http'):
                                        # å›¾ç‰‡URL
                                        print(f"âœ“ æ£€æµ‹åˆ°å›¾ç‰‡URL")
                                        images.append({
                                            'type': 'url',
                                            'data': image_data,
                                            'alt': 'ç”Ÿæˆçš„å›¾åƒ'
                                        })
                                    elif image_data.startswith('data:image'):
                                        # Base64å›¾ç‰‡ï¼ˆå¸¦data:imageå‰ç¼€ï¼‰
                                        print(f"âœ“ æ£€æµ‹åˆ°Base64å›¾ç‰‡ï¼ˆå¸¦å‰ç¼€ï¼‰")
                                        images.append({
                                            'type': 'base64',
                                            'data': image_data,
                                            'alt': 'ç”Ÿæˆçš„å›¾åƒ'
                                        })
                                    elif image_data.startswith('iVBORw0KGgo') or image_data.startswith('/9j/'):
                                        # çº¯Base64å›¾ç‰‡æ•°æ®ï¼ˆPNGæˆ–JPEGï¼‰
                                        print(f"âœ“ æ£€æµ‹åˆ°çº¯Base64å›¾ç‰‡æ•°æ®")
                                        # æ·»åŠ data:imageå‰ç¼€
                                        if image_data.startswith('iVBORw0KGgo'):
                                            # PNGæ ¼å¼
                                            base64_data = f"data:image/png;base64,{image_data}"
                                        else:
                                            # JPEGæ ¼å¼
                                            base64_data = f"data:image/jpeg;base64,{image_data}"
                                        
                                        images.append({
                                            'type': 'base64',
                                            'data': base64_data,
                                            'alt': 'ç”Ÿæˆçš„å›¾åƒ'
                                        })
                                    else:
                                        # å¯èƒ½æ˜¯å…¶ä»–æ ¼å¼çš„å­—ç¬¦ä¸²
                                        print(f"âš ï¸ æœªçŸ¥çš„å›¾ç‰‡æ•°æ®æ ¼å¼: {image_data[:50]}...")
                                        # å°è¯•ä½œä¸ºURLå¤„ç†
                                        images.append({
                                            'type': 'url',
                                            'data': image_data,
                                            'alt': 'ç”Ÿæˆçš„å›¾åƒ'
                                        })
                                elif isinstance(image_data, dict):
                                    # å¯èƒ½æ˜¯åŒ…å«å›¾ç‰‡ä¿¡æ¯çš„å­—å…¸
                                    print(f"å›¾ç‰‡æ•°æ®æ˜¯å­—å…¸: {image_data}")
                                    if 'url' in image_data:
                                        images.append({
                                            'type': 'url',
                                            'data': image_data['url'],
                                            'alt': 'ç”Ÿæˆçš„å›¾åƒ'
                                        })
                                    elif 'data' in image_data:
                                        images.append({
                                            'type': 'base64',
                                            'data': image_data['data'],
                                            'alt': 'ç”Ÿæˆçš„å›¾åƒ'
                                        })
                                else:
                                    print(f"âš ï¸ æœªçŸ¥çš„å›¾ç‰‡æ•°æ®ç±»å‹: {type(image_data)}")
                            else:
                                print(f"âš ï¸ æ²¡æœ‰æ‰¾åˆ°å›¾ç‰‡ç»“æœæ•°æ®")
                            
                            # æ£€æŸ¥çŠ¶æ€
                            if hasattr(raw_item, 'status'):
                                print(f"å›¾ç‰‡ç”ŸæˆçŠ¶æ€: {raw_item.status}")
        
        except Exception as e:
            print(f"æå–å›¾ç‰‡æ•°æ®æ—¶å‡ºé”™: {e}")
        
        return images
    
    def get_tool_display_name(self, tool_name: str) -> str:
        """è·å–å·¥å…·çš„ä¸­æ–‡æ˜¾ç¤ºåç§°"""
        tool_names = {
            'web_search': 'ç½‘ç»œæœç´¢',
            'web_search_tool': 'ç½‘ç»œæœç´¢',
            'image_generation': 'å›¾åƒç”Ÿæˆ',
            'image_generation_tool': 'å›¾åƒç”Ÿæˆ',
            'computer_tool': 'è®¡ç®—æœºå·¥å…·',
            'browser_tool': 'æµè§ˆå™¨å·¥å…·'
        }
        return tool_names.get(tool_name.lower(), tool_name)
    
    def get_tool_description(self, tool_name: str) -> str:
        """è·å–å·¥å…·çš„æè¿°ä¿¡æ¯"""
        tool_descriptions = {
            'web_search': 'æœç´¢ç½‘ç»œè·å–æœ€æ–°ä¿¡æ¯',
            'web_search_tool': 'æœç´¢ç½‘ç»œè·å–æœ€æ–°ä¿¡æ¯',
            'image_generation': 'ç”Ÿæˆå›¾åƒå’Œå›¾è¡¨',
            'image_generation_tool': 'ç”Ÿæˆå›¾åƒå’Œå›¾è¡¨',
            'computer_tool': 'æ‰§è¡Œè®¡ç®—å’Œæ¨¡æ‹Ÿ',
            'browser_tool': 'ä½¿ç”¨æµè§ˆå™¨è‡ªåŠ¨åŒ–'
        }
        return tool_descriptions.get(tool_name.lower(), 'æœªçŸ¥å·¥å…·')


# =============================================================================
# MCP ç›¸å…³å·¥å…·å‡½æ•°
# =============================================================================

def validate_mcp_connectivity(config: Dict[str, Any]) -> (bool, str):
    """æ ¡éªŒ MCP æ˜¯å¦å¯è¿æ¥ï¼Œè¿”å› (æ˜¯å¦æˆåŠŸ, é”™è¯¯ä¿¡æ¯)"""
    try:
        if not isinstance(config, dict):
            return False, "é…ç½®éœ€ä¸ºJSONå¯¹è±¡"
        url = config.get('url')
        if not url:
            return False, "ç¼ºå°‘ url å­—æ®µ"
        headers = config.get('headers') or {}
        timeout = float(config.get('timeout', 10))

        # ä½¿ç”¨ GET è¿›è¡Œè¿é€šæ€§æ¢æµ‹ï¼ˆéƒ¨åˆ†å®ç°ä¼šè¦æ±‚POSTï¼Œè¿™é‡Œä»¥GETä¸ºæ¢æµ‹ï¼‰
        resp = requests.get(url, headers=headers, timeout=timeout)
        if 200 <= resp.status_code < 300:
            return True, ""
        # è¿”å›éƒ¨åˆ†å“åº”ä½“å¸®åŠ©å®šä½
        body = resp.text[:300] if isinstance(resp.text, str) else ''
        return False, f"HTTP {resp.status_code}: {body}"
    except requests.exceptions.RequestException as e:
        return False, f"ç½‘ç»œå¼‚å¸¸: {str(e)}"
    except Exception as e:
        return False, f"æœªçŸ¥é”™è¯¯: {str(e)}"


# =============================================================================
# å·¥å…·å‡½æ•°
# =============================================================================

def allowed_file(filename: str) -> bool:
    """æ£€æŸ¥æ–‡ä»¶ç±»å‹æ˜¯å¦å…è®¸"""
    return '.' in filename and filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS


# =============================================================================
# Flask è·¯ç”±
# =============================================================================

@app.route('/')
def index():
    """ä¸»é¡µè·¯ç”± - æ¸²æŸ“å‰ç«¯é¡µé¢"""
    return render_template('index.html')


@app.route('/api/chat', methods=['POST'])
def chat():
    """èŠå¤©APIè·¯ç”± - å¤„ç†ç”¨æˆ·æ¶ˆæ¯"""
    data = request.get_json()
    user_message = data.get('message', '').strip()
    conversation_id = data.get('conversation_id')
    if not conversation_id:
        conversation_id = str(uuid.uuid4())
        print(f"ğŸ†• åˆ›å»ºæ–°å¯¹è¯ID: {conversation_id}")
    use_web_search = data.get('use_web_search', False)
    region = data.get('region', 'auto')
    file_id = data.get('file_id')
    mode = data.get('mode', 'auto')
    
    # è°ƒè¯•ä¿¡æ¯
    print(f"ğŸ“¨ æ”¶åˆ°æ¶ˆæ¯: {user_message}")
    print(f"ğŸ“ æ–‡ä»¶ID: {file_id}")
    print(f"ğŸ’¬ å¯¹è¯ID: {conversation_id}")
    
    # å…è®¸ç©ºæ¶ˆæ¯ï¼šè‹¥æºå¸¦éŸ³é¢‘æ–‡ä»¶åˆ™è‡ªåŠ¨ç”Ÿæˆé»˜è®¤é—®é¢˜
    # åœ¨æ²¡æœ‰æ–‡ä»¶ä¹Ÿæ²¡æœ‰æ¶ˆæ¯çš„æƒ…å†µä¸‹ä»ç„¶æŠ¥é”™
    if not user_message:
        auto_msg_from_audio = False
        if file_id and file_id in uploaded_files:
            fpath = uploaded_files[file_id]['path']
            fext = os.path.splitext(fpath)[1].lower().strip('.')
            if fext in {'mp3','wav','m4a','webm','ogg'}:
                user_message = 'è¯·åŸºäºè¯¥è¯­éŸ³å†…å®¹ç»™å‡ºå®Œæ•´æ‘˜è¦ã€è¦ç‚¹åˆ—è¡¨ä¸å…³é”®ä¿¡æ¯ã€‚'
                auto_msg_from_audio = True
        if not user_message:
            return jsonify({'error': 'æ¶ˆæ¯ä¸èƒ½ä¸ºç©º'}), 400
    
    # è·å–æˆ–åˆ›å»ºå¯¹è¯å†å²
    if conversation_id not in conversation_history:
        conversation_history[conversation_id] = []
    
    # å¦‚æœæºå¸¦çš„æ˜¯éŸ³é¢‘æ–‡ä»¶ï¼Œåˆ™åœ¨è¿›å…¥å¯¹è¯æµç¨‹å‰å…ˆåšè‡ªåŠ¨è½¬å†™
    auto_transcribed = False
    if file_id and file_id in uploaded_files:
        file_info_auto = uploaded_files[file_id]
        file_path_auto = file_info_auto['path']
        name_ext = os.path.splitext(file_info_auto.get('name',''))[1].lower().strip('.')
        path_ext = os.path.splitext(file_path_auto)[1].lower().strip('.')
        ext_auto = name_ext or path_ext
        print(f"ğŸ” è‡ªåŠ¨è½¬å†™æ£€æŸ¥ï¼šext={ext_auto}, path={file_path_auto}")
        if ext_auto in {'mp3','wav','m4a','webm','ogg'}:
            try:
                print(f"ğŸ™ï¸ æ£€æµ‹åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œè‡ªåŠ¨è½¬å†™: {file_info_auto['name']}")
                user_message = _transcribe_file_local(file_path_auto) or user_message
                auto_transcribed = True
                print(f"ğŸ“ è½¬å†™æ–‡æœ¬: {user_message[:120]}...")
            except Exception as e:
                print(f"âŒ è‡ªåŠ¨è½¬å†™å¤±è´¥: {e}")
    
    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²ï¼ˆåŒ…å«æ–‡ä»¶ä¿¡æ¯ï¼‰
    user_message_data = {
        'timestamp': datetime.now().isoformat(),
        'type': 'user',
        'message': user_message
    }
    
    # å¦‚æœæœ‰æ–‡ä»¶ï¼Œæ·»åŠ æ–‡ä»¶ä¿¡æ¯ï¼ˆåŒä¸€ä¼šè¯å†…å»é‡ï¼šå·²å‡ºç°è¿‡çš„ file_id ä¸å†é‡å¤é™„åŠ ï¼‰
    if file_id and file_id in uploaded_files:
        # æ£€æŸ¥è¯¥ä¼šè¯å†å²ä¸­æ˜¯å¦å·²å‡ºç°è¿‡ç›¸åŒçš„ file_id
        history_has_same_file = any(
            isinstance(m, dict) and m.get('file_id') == file_id
            for m in conversation_history.get(conversation_id, [])
        )
        if not history_has_same_file:
            file_info = uploaded_files[file_id]
            user_message_data['file_id'] = file_id
            user_message_data['file_name'] = file_info['name']
            user_message_data['file_type'] = os.path.splitext(file_info['name'])[1].lower()
            print(f"âœ… æ–‡ä»¶ä¿¡æ¯å·²æ·»åŠ åˆ°æ¶ˆæ¯: {file_info['name']}")
        else:
            print(f"â†©ï¸ åŒä¼šè¯å·²åŒ…å«è¯¥æ–‡ä»¶ID {file_id}ï¼Œè·³è¿‡é‡å¤é™„åŠ åˆ°æ¶ˆæ¯")
    else:
        print(f"âŒ æ–‡ä»¶ID {file_id} æœªæ‰¾åˆ°æˆ–ä¸ºç©º")
        print(f"ğŸ“ å½“å‰ä¸Šä¼ çš„æ–‡ä»¶: {list(uploaded_files.keys())}")
    
    if auto_transcribed:
        user_message_data['transcribed_from_audio'] = True
        user_message_data['transcribed_text'] = user_message
    conversation_history[conversation_id].append(user_message_data)
    # ä»…ä¿ç•™æœ€è¿‘10æ¡ï¼Œå¹¶æŒä¹…åŒ–
    conversation_history[conversation_id] = conversation_history[conversation_id][-10:]
    _save_conversations()
    print(f"ğŸ’¾ æ¶ˆæ¯å·²ä¿å­˜åˆ°å¯¹è¯å†å²ï¼ŒåŒ…å«æ–‡ä»¶ä¿¡æ¯: {'file_id' in user_message_data}")
    
    # ä½¿ç”¨ä¸­å¿ƒæ™ºèƒ½ä½“å¤„ç†ç”¨æˆ·é—®é¢˜
    loop = asyncio.new_event_loop()
    asyncio.set_event_loop(loop)
    try:
        ai_result = loop.run_until_complete(ai_app.process_user_question(user_message, conversation_id, file_id))
    finally:
        loop.close()
    
    # æå–å“åº”å†…å®¹å’Œæ™ºèƒ½ä½“ä¿¡æ¯
    if isinstance(ai_result, dict):
        response_content = ai_result['content']
        agent_name = ai_result['agent_name']
        agent_id = ai_result['agent_id']
        tools_used = ai_result.get('tools_used', [])
        images = ai_result.get('images', [])
    else:
        # å…¼å®¹æ—§æ ¼å¼
        response_content = ai_result
        agent_name = "æœªçŸ¥æ™ºèƒ½ä½“"
        agent_id = "unknown"
        tools_used = []
        images = []
    
    # æ·»åŠ AIå›å¤åˆ°å†å²
    conversation_history[conversation_id].append({
        'timestamp': datetime.now().isoformat(),
        'type': 'assistant',
        'message': response_content,
        'agent_name': agent_name,
        'agent_id': agent_id,
        'tools_used': tools_used,
        'images': images
    })
    conversation_history[conversation_id] = conversation_history[conversation_id][-10:]
    _save_conversations()
    
    return jsonify({
        'response': response_content,
        'agent_name': agent_name,
        'agent_id': agent_id,
        'tools_used': tools_used,
        'images': images,
        'conversation_id': conversation_id
    })


@app.route('/api/upload', methods=['POST'])
def upload_file():
    """æ–‡ä»¶ä¸Šä¼ APIè·¯ç”±"""
    if 'file' not in request.files:
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
    
    file = request.files['file']
    if file.filename == '':
        return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©æ–‡ä»¶'}), 400
    
    if file and allowed_file(file.filename):
        filename = secure_filename(file.filename)
        # è‹¥ secure_filename å»æ‰äº†æ‰©å±•åï¼Œåˆ™æ ¹æ® mimetype è¿½åŠ ï¼ˆéŸ³é¢‘åœºæ™¯å°¤ä¸ºå¸¸è§ï¼‰
        base, ext = os.path.splitext(filename)
        if not ext and (file.mimetype or '').startswith('audio/'):
            mime_tail = (file.mimetype.split('/')[-1] or '').lower()
            # è§„èŒƒåŒ–å¸¸è§ audio/* åˆ°æ–‡ä»¶åç¼€
            mime_map = {
                'x-m4a': 'm4a', 'm4a': 'm4a',
                'mpeg': 'mp3', 'mp3': 'mp3',
                'wav': 'wav', 'x-wav': 'wav', 'wave': 'wav',
                'mp4': 'mp4', 'x-mp4': 'mp4',
                'ogg': 'ogg', 'oga': 'ogg',
                'webm': 'webm'
            }
            norm = mime_map.get(mime_tail.lstrip('x-'), mime_map.get(mime_tail, 'm4a'))
            filename = base + '.' + norm
        # æ·»åŠ æ—¶é—´æˆ³é¿å…æ–‡ä»¶åå†²çª
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"{timestamp}_{filename}"
        filepath = os.path.join(app.config['UPLOAD_FOLDER'], filename)
        file.save(filepath)
        
        # ç”Ÿæˆæ–‡ä»¶ID
        file_id = str(uuid.uuid4())
        
        # ä¿å­˜æ–‡ä»¶ä¿¡æ¯
        uploaded_files[file_id] = {
            'name': file.filename,
            'path': filepath,
            'id': file_id,
            'upload_time': datetime.now().isoformat()
        }
        
        return jsonify({
            'file_id': file_id,
            'filename': file.filename,
            'message': 'æ–‡ä»¶ä¸Šä¼ æˆåŠŸ'
        })
    
    return jsonify({'error': 'ä¸æ”¯æŒçš„æ–‡ä»¶ç±»å‹'}), 400


@app.route('/api/transcribe', methods=['POST'])
def transcribe_audio():
    """è¯­éŸ³è½¬æ–‡å­—ï¼šæ¥æ”¶éŸ³é¢‘æ–‡ä»¶æˆ–å·²ä¸Šä¼ çš„ file_idï¼Œè¿”å›æ–‡æœ¬"""
    if 'file' in request.files:
        # ç›´æ¥ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶
        audio = request.files['file']
        if audio.filename == '':
            return jsonify({'error': 'æ²¡æœ‰é€‰æ‹©éŸ³é¢‘æ–‡ä»¶'}), 400
        # å­˜ä¸´æ—¶è·¯å¾„
        temp_name = secure_filename(audio.filename)
        temp_path = os.path.join(app.config['UPLOAD_FOLDER'], f"tmp_{uuid.uuid4()}_{temp_name}")
        audio.save(temp_path)
        try:
            text = _transcribe_file_local(temp_path)
            return jsonify({'text': text})
        finally:
            if os.path.exists(temp_path):
                os.remove(temp_path)
    else:
        data = request.get_json() or {}
        file_id = data.get('file_id')
        if not file_id or file_id not in uploaded_files:
            return jsonify({'error': 'ç¼ºå°‘æœ‰æ•ˆçš„ file_id æˆ–æ–‡ä»¶ä¸å­˜åœ¨'}), 400
        file_path = uploaded_files[file_id]['path']
        # æ ¡éªŒæ‰©å±•å
        ext = os.path.splitext(file_path)[1].lower().strip('.')
        if ext not in {'mp3','wav','m4a','webm','ogg'}:
            return jsonify({'error': 'è¯¥æ–‡ä»¶ä¸æ˜¯å—æ”¯æŒçš„éŸ³é¢‘ç±»å‹'}), 400
        text = _transcribe_file_local(file_path)
        return jsonify({'text': text})


@app.route('/api/files', methods=['GET'])
def get_files():
    """è·å–å·²ä¸Šä¼ æ–‡ä»¶åˆ—è¡¨"""
    files_list = []
    for file_id, info in uploaded_files.items():
        files_list.append({
            'id': file_id,
            'name': info['name'],
            'upload_time': info['upload_time']
        })
    return jsonify({'files': files_list})


@app.route('/api/files/<file_id>', methods=['DELETE'])
def delete_file(file_id):
    """åˆ é™¤æ–‡ä»¶"""
    if file_id in uploaded_files:
        file_info = uploaded_files[file_id]
        # åˆ é™¤æœ¬åœ°æ–‡ä»¶
        if os.path.exists(file_info['path']):
            os.remove(file_info['path'])
        # ä»å†…å­˜ä¸­åˆ é™¤
        del uploaded_files[file_id]
        return jsonify({'message': 'æ–‡ä»¶åˆ é™¤æˆåŠŸ'})
    return jsonify({'error': 'æ–‡ä»¶ä¸å­˜åœ¨'}), 404


@app.route('/api/conversations', methods=['GET'])
def get_conversations():
    """è·å–å¯¹è¯å†å²åˆ—è¡¨"""
    conversations = []
    for conv_id, messages in conversation_history.items():
        if messages:
            first_message = messages[0]['message']
            # æˆªå–å‰50ä¸ªå­—ç¬¦ä½œä¸ºæ ‡é¢˜
            title = first_message[:50] + '...' if len(first_message) > 50 else first_message
            conversations.append({
                'id': conv_id,
                'title': title,
                'last_message_time': messages[-1]['timestamp'],
                'message_count': len(messages)
            })
    
    # æŒ‰æ—¶é—´æ’åº
    conversations.sort(key=lambda x: x['last_message_time'], reverse=True)
    return jsonify({'conversations': conversations})


@app.route('/api/conversations/<conversation_id>', methods=['GET'])
def get_conversation(conversation_id):
    """è·å–ç‰¹å®šå¯¹è¯çš„è¯¦ç»†å†…å®¹"""
    if conversation_id in conversation_history:
        return jsonify({'messages': conversation_history[conversation_id]})
    return jsonify({'error': 'å¯¹è¯ä¸å­˜åœ¨'}), 404


@app.route('/api/conversations/<conversation_id>', methods=['DELETE'])
def delete_conversation(conversation_id):
    """åˆ é™¤å¯¹è¯"""
    if conversation_id in conversation_history:
        del conversation_history[conversation_id]
        _save_conversations()
        return jsonify({'message': 'å¯¹è¯åˆ é™¤æˆåŠŸ'})
    return jsonify({'error': 'å¯¹è¯ä¸å­˜åœ¨'}), 404


# =============================================================================
# MCP ç®¡ç† APIï¼ˆæ ¡éªŒ+CRUDï¼Œå ä½å®ç°å†…å­˜å­˜å‚¨ï¼‰
# =============================================================================

@app.route('/api/mcps', methods=['GET'])
def list_mcps():
    return jsonify({'mcps': list(mcp_registry.values())})


@app.route('/api/mcps', methods=['POST'])
def create_mcp():
    data = request.get_json() or {}
    name = (data.get('name') or '').strip()
    description = (data.get('description') or '').strip()
    enabled = bool(data.get('enabled', True))
    config = data.get('config') or {}

    if not name:
        return jsonify({'error': 'åç§°ä¸èƒ½ä¸ºç©º'}), 400

    # æ ¡éªŒè¿é€šæ€§
    ok, err = validate_mcp_connectivity(config)
    if not ok:
        return jsonify({'error': f'æ ¡éªŒå¤±è´¥ï¼š{err}'}), 400

    mcp_id = str(uuid.uuid4())
    mcp_info = {
        'id': mcp_id,
        'name': name,
        'description': description,
        'enabled': enabled,
        'config': config,
        'created_at': datetime.now().isoformat()
    }
    mcp_registry[mcp_id] = mcp_info
    _save_mcp_registry()
    return jsonify({'message': 'åˆ›å»ºæˆåŠŸ', 'mcp': mcp_info})


@app.route('/api/mcps/<mcp_id>', methods=['PUT'])
def update_mcp(mcp_id):
    if mcp_id not in mcp_registry:
        return jsonify({'error': 'MCP ä¸å­˜åœ¨'}), 404
    data = request.get_json() or {}
    name = (data.get('name') or '').strip()
    description = (data.get('description') or '').strip()
    enabled = bool(data.get('enabled', True))
    config = data.get('config') or {}

    if not name:
        return jsonify({'error': 'åç§°ä¸èƒ½ä¸ºç©º'}), 400

    # ä¿®æ”¹é…ç½®æ—¶ä¹Ÿæ ¡éªŒè¿é€šæ€§
    ok, err = validate_mcp_connectivity(config)
    if not ok:
        return jsonify({'error': f'æ ¡éªŒå¤±è´¥ï¼š{err}'}), 400

    mcp = mcp_registry[mcp_id]
    mcp.update({
        'name': name,
        'description': description,
        'enabled': enabled,
        'config': config,
        'updated_at': datetime.now().isoformat()
    })
    _save_mcp_registry()
    return jsonify({'message': 'æ›´æ–°æˆåŠŸ', 'mcp': mcp})


@app.route('/api/mcps/<mcp_id>/enable', methods=['PATCH'])
def enable_mcp(mcp_id):
    if mcp_id not in mcp_registry:
        return jsonify({'error': 'MCP ä¸å­˜åœ¨'}), 404
    data = request.get_json() or {}
    enabled = bool(data.get('enabled', True))
    mcp_registry[mcp_id]['enabled'] = enabled
    mcp_registry[mcp_id]['updated_at'] = datetime.now().isoformat()
    _save_mcp_registry()
    return jsonify({'message': 'çŠ¶æ€å·²æ›´æ–°'})


@app.route('/api/mcps/<mcp_id>', methods=['DELETE'])
def delete_mcp_api(mcp_id):
    if mcp_id not in mcp_registry:
        return jsonify({'error': 'MCP ä¸å­˜åœ¨'}), 404
    del mcp_registry[mcp_id]
    _save_mcp_registry()
    return jsonify({'message': 'åˆ é™¤æˆåŠŸ'})


@app.route('/api/clear', methods=['POST'])
def clear_all():
    """æ¸…é™¤æ‰€æœ‰æ•°æ®"""
    conversation_history.clear()
    # æ¸…ç†ä¸Šä¼ çš„æ–‡ä»¶
    for file_id, info in uploaded_files.items():
        if os.path.exists(info['path']):
            os.remove(info['path'])
    uploaded_files.clear()
    _save_conversations()
    return jsonify({'message': 'æ‰€æœ‰æ•°æ®å·²æ¸…é™¤'})


# =============================================================================
# ä¸»ç¨‹åºå…¥å£
# =============================================================================

# åˆå§‹åŒ–AIåº”ç”¨
ai_app = AIWebApp()
_load_mcp_registry()
_load_conversations()

if __name__ == '__main__':
    print("ğŸ“ å¯åŠ¨AIå…¨èƒ½æ•™å¸ˆWebç³»ç»Ÿ...")
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5000")
    print("ğŸ“ æ”¯æŒæ–‡ä»¶ä¸Šä¼ åŠŸèƒ½")
    print("ğŸ’¬ æ”¯æŒå¤šè½®å¯¹è¯äº¤äº’")
    print("ğŸ”§ æ”¯æŒå¤šæ™ºèƒ½ä½“åä½œå’Œå·¥å…·è°ƒç”¨")
    print("ğŸš€ ç³»ç»Ÿå·²å°±ç»ªï¼Œå¼€å§‹æœåŠ¡...")
    
    app.run(debug=True, host='0.0.0.0', port=5000)
